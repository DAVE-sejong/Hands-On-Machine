{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package loaded\n"
     ]
    }
   ],
   "source": [
    "# Packages Load\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.__version__\n",
    "print(\"package loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heon1\\Desktop\\디지털경영론2조\n"
     ]
    }
   ],
   "source": [
    "# os\n",
    "cwd = (r'C:\\Users\\heon1\\Desktop\\디지털경영론2조')\n",
    "os.chdir(cwd)\n",
    "os.getcwd()\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'Close', 'High', 'Low', 'Adj Close', 'Volume', 'wti',\n",
       "       'gold', 'nasdac', 'cospi', 'usd', 'avg_5_adj', 'avg_5_vol', 'adjrate',\n",
       "       'classification'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(cwd+ r\"\\HM.csv\") #encoding = 'UTF-8')\n",
    "df.describe()\n",
    "df\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>wti</th>\n",
       "      <th>gold</th>\n",
       "      <th>nasdac</th>\n",
       "      <th>cospi</th>\n",
       "      <th>usd</th>\n",
       "      <th>avg_5_adj</th>\n",
       "      <th>avg_5_vol</th>\n",
       "      <th>adjrate</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2.132000e+03</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>2132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>249723.537615</td>\n",
       "      <td>249440.177110</td>\n",
       "      <td>254611.274072</td>\n",
       "      <td>244804.018544</td>\n",
       "      <td>249017.748600</td>\n",
       "      <td>9.505430e+04</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>248774.323594</td>\n",
       "      <td>95047.653471</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.468105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>196670.555122</td>\n",
       "      <td>196041.207215</td>\n",
       "      <td>200456.359258</td>\n",
       "      <td>192586.300677</td>\n",
       "      <td>195913.207264</td>\n",
       "      <td>1.262614e+05</td>\n",
       "      <td>0.021122</td>\n",
       "      <td>0.013499</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.009339</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>195730.281669</td>\n",
       "      <td>101680.855370</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.499099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>38008.500000</td>\n",
       "      <td>38008.500000</td>\n",
       "      <td>38604.699220</td>\n",
       "      <td>37561.300780</td>\n",
       "      <td>37845.035160</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.086700</td>\n",
       "      <td>-0.093500</td>\n",
       "      <td>-0.069000</td>\n",
       "      <td>-0.062200</td>\n",
       "      <td>-0.023700</td>\n",
       "      <td>38527.704690</td>\n",
       "      <td>8192.200000</td>\n",
       "      <td>-0.183487</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>72460.175782</td>\n",
       "      <td>72460.175782</td>\n",
       "      <td>73714.175780</td>\n",
       "      <td>70915.277347</td>\n",
       "      <td>72148.541017</td>\n",
       "      <td>3.891175e+04</td>\n",
       "      <td>-0.010900</td>\n",
       "      <td>-0.004300</td>\n",
       "      <td>-0.004200</td>\n",
       "      <td>-0.004200</td>\n",
       "      <td>-0.003100</td>\n",
       "      <td>72286.600785</td>\n",
       "      <td>45358.750000</td>\n",
       "      <td>-0.013891</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>128530.000000</td>\n",
       "      <td>127943.000000</td>\n",
       "      <td>130486.500000</td>\n",
       "      <td>125987.000000</td>\n",
       "      <td>127392.750000</td>\n",
       "      <td>6.113750e+04</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>126185.165650</td>\n",
       "      <td>65873.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>418500.000000</td>\n",
       "      <td>418125.000000</td>\n",
       "      <td>429412.000000</td>\n",
       "      <td>410421.250000</td>\n",
       "      <td>418125.000000</td>\n",
       "      <td>1.032990e+05</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>418382.400000</td>\n",
       "      <td>99373.650000</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>761784.000000</td>\n",
       "      <td>745932.000000</td>\n",
       "      <td>772352.000000</td>\n",
       "      <td>722154.000000</td>\n",
       "      <td>742723.937500</td>\n",
       "      <td>2.004437e+06</td>\n",
       "      <td>0.146800</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>723257.012500</td>\n",
       "      <td>996802.000000</td>\n",
       "      <td>0.299818</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open          Close           High            Low  \\\n",
       "count    2132.000000    2132.000000    2132.000000    2132.000000   \n",
       "mean   249723.537615  249440.177110  254611.274072  244804.018544   \n",
       "std    196670.555122  196041.207215  200456.359258  192586.300677   \n",
       "min     38008.500000   38008.500000   38604.699220   37561.300780   \n",
       "25%     72460.175782   72460.175782   73714.175780   70915.277347   \n",
       "50%    128530.000000  127943.000000  130486.500000  125987.000000   \n",
       "75%    418500.000000  418125.000000  429412.000000  410421.250000   \n",
       "max    761784.000000  745932.000000  772352.000000  722154.000000   \n",
       "\n",
       "           Adj Close        Volume          wti         gold       nasdac  \\\n",
       "count    2132.000000  2.132000e+03  2132.000000  2132.000000  2132.000000   \n",
       "mean   249017.748600  9.505430e+04     0.000083     0.001335     0.000561   \n",
       "std    195913.207264  1.262614e+05     0.021122     0.013499     0.010699   \n",
       "min     37845.035160  0.000000e+00    -0.086700    -0.093500    -0.069000   \n",
       "25%     72148.541017  3.891175e+04    -0.010900    -0.004300    -0.004200   \n",
       "50%    127392.750000  6.113750e+04     0.000400     0.000300     0.000900   \n",
       "75%    418125.000000  1.032990e+05     0.010900     0.005525     0.006300   \n",
       "max    742723.937500  2.004437e+06     0.146800     0.154600     0.058400   \n",
       "\n",
       "             cospi          usd      avg_5_adj      avg_5_vol      adjrate  \\\n",
       "count  2132.000000  2132.000000    2132.000000    2132.000000  2132.000000   \n",
       "mean      0.000144     0.000019  248774.323594   95047.653471     0.001459   \n",
       "std       0.009339     0.005314  195730.281669  101680.855370     0.029692   \n",
       "min      -0.062200    -0.023700   38527.704690    8192.200000    -0.183487   \n",
       "25%      -0.004200    -0.003100   72286.600785   45358.750000    -0.013891   \n",
       "50%       0.000300    -0.000100  126185.165650   65873.700000     0.000000   \n",
       "75%       0.005200     0.003000  418382.400000   99373.650000     0.014171   \n",
       "max       0.050200     0.033300  723257.012500  996802.000000     0.299818   \n",
       "\n",
       "       classification  \n",
       "count     2132.000000  \n",
       "mean         0.468105  \n",
       "std          0.499099  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          1.000000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() #open high low adjcloseavg adj # volumne avg vole#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Open', 'Close', 'High', 'Low', 'Adj Close', 'Volume', 'wti', 'gold',\n",
      "       'nasdac', 'cospi', 'usd', 'avg_5_adj', 'avg_5_vol', 'adjrate',\n",
      "       'classification'],\n",
      "      dtype='object')\n",
      "Open              float64\n",
      "Close             float64\n",
      "High              float64\n",
      "Low               float64\n",
      "Adj Close         float64\n",
      "Volume              int64\n",
      "wti               float64\n",
      "gold              float64\n",
      "nasdac            float64\n",
      "cospi             float64\n",
      "usd               float64\n",
      "avg_5_adj         float64\n",
      "avg_5_vol         float64\n",
      "adjrate           float64\n",
      "classification      int64\n",
      "dtype: object\n",
      "(2132, 15)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "df.drop(['Date'],axis=1, inplace=True)\n",
    "print(df.columns)\n",
    "print(df.dtypes)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "def min_max_scaling(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.min()) / (x_np.max() - x_np.min() + 1e-7)  # 1e-7은 0으로 나누는 오류 예방차원\n",
    "\n",
    "# 정규화하기 이전의 org_x값과 되돌리고 싶은 x를 입력하면 역정규화된 값을 리턴한다\n",
    "def reverse_min_max_scaling(org_x, x):\n",
    "    org_x_np = np.asarray(org_x)\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np * (org_x_np.max() - org_x_np.min() + 1e-7)) + org_x_np.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2132, 5)\n",
      "(2132,)\n",
      "(2132,)\n",
      "(2132,)\n"
     ]
    }
   ],
   "source": [
    "norm_price = min_max_scaling(df[df.columns[0:5]])\n",
    "norm_price2 = min_max_scaling(df[df.columns[-4]])\n",
    "volumn = min_max_scaling(df[df.columns[5]])\n",
    "volumn2 = min_max_scaling(df[df.columns[-3]])\n",
    "print(norm_price.shape)\n",
    "print(volumn.shape)\n",
    "print(norm_price2.shape)\n",
    "print(volumn2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wti = np.reshape(min_max_scaling(df[df.columns[6]]), ((-1,1)))\n",
    "gold = np.reshape(min_max_scaling(df[df.columns[7]]), ((-1,1)))\n",
    "nasdac = np.reshape(min_max_scaling(df[df.columns[8]]), ((-1,1)))\n",
    "cospi = np.reshape(min_max_scaling(df[df.columns[9]]), ((-1,1)))\n",
    "usd = np.reshape(min_max_scaling(df[df.columns[10]]), ((-1,1)))\n",
    "volumn = np.reshape(volumn,((-1,1)))\n",
    "volumn2 = np.reshape(volumn2,((-1,1)))\n",
    "norm_price2 = np.reshape(norm_price2, ((-1,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2132, 13)\n",
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# x,y 분할\n",
    "x= np.concatenate((norm_price, norm_price2, volumn, volumn2, wti, gold, nasdac, cospi, usd), axis=1)\n",
    "y= np.array(df[df.columns[-1]])\n",
    "print(x.shape)\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "input_data_column_cnt = 13  # 입력데이터의 컬럼 개수(Variable 개수)\n",
    "output_data_column_cnt = 1  # 결과데이터의 컬럼 개수\n",
    "seq_length = 28  # 1개 시퀀스의 길이(시계열데이터 입력 개수)\n",
    "rnn_cell_hidden_dim = 20  # 각 셀의 (hidden)출력 크기\n",
    "forget_bias = 0.8  # 망각편향(기본값 1.0)\n",
    "num_stacked_layers = 5  # stacked LSTM layers 개수\n",
    "keep_prob = 0.8  # dropout할 때 keep할 비율\n",
    "epoch_num = 1000  # 에폭 횟수(학습용전체데이터를 몇 회 반복해서 학습할 것인가 입력)\n",
    "learning_rate = 0.0001  # 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03002188 0.03728953 0.03811752 0.02992988 0.03690931 0.03367484\n",
      "  0.06543683 0.10120757 0.3027836  0.3978233  0.52590226 0.55338029\n",
      "  0.32982398]\n",
      " [0.03655368 0.03811752 0.04271734 0.03600168 0.03773375 0.03485439\n",
      "  0.05889933 0.09440226 0.41284779 0.36799663 0.60047049 0.58540873\n",
      "  0.3999993 ]\n",
      " [0.03830152 0.03756553 0.03903751 0.03646167 0.03718412 0.03587665\n",
      "  0.02165097 0.09219087 0.30663798 0.36195068 0.44426967 0.50889634\n",
      "  0.54034993]\n",
      " [0.03710567 0.03756553 0.03876151 0.03618568 0.03718412 0.03689892\n",
      "  0.02390247 0.08266861 0.25224829 0.38129771 0.30533728 0.43861171\n",
      "  0.62280592]\n",
      " [0.03636967 0.03535769 0.03793352 0.03535769 0.03498578 0.0380785\n",
      "  0.02360463 0.07017652 0.24625257 0.4349051  0.47645175 0.36921675\n",
      "  0.47543776]\n",
      " [0.03581768 0.03379371 0.03627768 0.03379371 0.03342852 0.03733144\n",
      "  0.02910743 0.05544473 0.35160585 0.37726708 0.48116132 0.6797147\n",
      "  0.37719232]\n",
      " [0.03324185 0.03811752 0.03811752 0.03314985 0.03773375 0.03733144\n",
      "  0.01895196 0.03924582 0.36274074 0.408706   0.57221305 0.53825575\n",
      "  0.46666585]\n",
      " [0.03784152 0.03903751 0.0395895  0.03655368 0.03864978 0.03764601\n",
      "  0.02162652 0.0392359  0.40128462 0.38371609 0.64050185 0.61298878\n",
      "  0.25263114]\n",
      " [0.0399575  0.04271734 0.04317733 0.03903751 0.04231378 0.03874694\n",
      "  0.04438304 0.0475409  0.35160585 0.38694059 0.56357884 0.58896745\n",
      "  0.38596424]\n",
      " [0.04225734 0.04087749 0.04363733 0.03885351 0.04048185 0.03992652\n",
      "  0.02784223 0.04925927 0.31520329 0.3901651  0.41130266 0.64234818\n",
      "  0.3999993 ]\n",
      " [0.04133735 0.03830152 0.04133735 0.03820951 0.03791695 0.04088984\n",
      "  0.03203144 0.05044498 0.31563156 0.35550167 0.54474055 0.53291768\n",
      "  0.58070074]\n",
      " [0.03894551 0.04087749 0.04225734 0.03848552 0.04048185 0.04147964\n",
      "  0.02290768 0.05204905 0.35032105 0.37605789 0.46938739 0.51423442\n",
      "  0.38771862]\n",
      " [0.04179735 0.04823714 0.04915699 0.04087749 0.04780984 0.04344559\n",
      "  0.06705324 0.07046987 0.28522472 0.39298654 0.41130266 0.51690345\n",
      "  0.56666567]\n",
      " [0.04777714 0.04731715 0.05007698 0.04455732 0.0468938  0.04442857\n",
      "  0.04411812 0.07036244 0.42441095 0.40225699 0.60753484 0.42348717\n",
      "  0.48420968]\n",
      " [0.04915699 0.04685715 0.04915699 0.04409732 0.04643578 0.04570642\n",
      "  0.03449547 0.07306037 0.42098483 0.36356293 0.45761346 0.5275796\n",
      "  0.32631522]\n",
      " [0.04547717 0.04685715 0.04915699 0.04455732 0.04643578 0.04753475\n",
      "  0.02239781 0.06915388 0.47708759 0.37887933 0.67111407 0.55249061\n",
      "  0.48947283]\n",
      " [0.04869713 0.04777714 0.04869713 0.04455732 0.04735182 0.0490092\n",
      "  0.01247782 0.0649245  0.34432533 0.38049158 0.41915195 0.71085346\n",
      "  0.36315726]\n",
      " [0.04731715 0.05007698 0.05099697 0.04593716 0.04964177 0.04940237\n",
      "  0.02840149 0.04925098 0.21199134 0.41354276 0.51962283 0.46530208\n",
      "  0.5122798 ]\n",
      " [0.04961698 0.05513678 0.05559678 0.04915699 0.05467981 0.05107342\n",
      "  0.03817381 0.04684052 0.48993555 0.37041501 0.77472467 0.66547983\n",
      "  0.20350841]\n",
      " [0.05467679 0.05513678 0.05605677 0.05283695 0.05467981 0.05284277\n",
      "  0.02435198 0.04272727 0.43554585 0.39379267 0.62480328 0.60943006\n",
      "  0.34912219]\n",
      " [0.05467679 0.05513678 0.05651677 0.05421679 0.05467981 0.05461212\n",
      "  0.02775692 0.04490042 0.34732319 0.36960888 0.66169493 0.57473258\n",
      "  0.32631522]\n",
      " [0.05145696 0.05145696 0.05283695 0.05053697 0.05101582 0.0553985\n",
      "  0.01918893 0.04762182 0.34218401 0.40306312 0.45447374 0.53024864\n",
      "  0.50350789]\n",
      " [0.05099697 0.05145696 0.0537568  0.05007698 0.05101582 0.0556934\n",
      "  0.02373933 0.04573129 0.40471075 0.37122113 0.61224442 0.5106757\n",
      "  0.32982398]\n",
      " [0.05145696 0.05283695 0.0537568  0.04915699 0.05238987 0.05520193\n",
      "  0.03069041 0.04269672 0.34732319 0.35550167 0.56750348 0.57918098\n",
      "  0.34736781]\n",
      " [0.05191696 0.05145696 0.0532968  0.04961698 0.05101582 0.05441556\n",
      "  0.03181492 0.04572299 0.49807259 0.36275681 0.56357884 0.64412754\n",
      "  0.38771862]\n",
      " [0.05283695 0.04915699 0.05283695 0.04777714 0.04872573 0.05313768\n",
      "  0.02913536 0.04628196 0.41284779 0.37887933 0.69309208 0.63345139\n",
      "  0.3280696 ]\n",
      " [0.04823714 0.04731715 0.04915699 0.04685715 0.0468938  0.052253\n",
      "  0.02779434 0.04977151 0.34946452 0.45667051 0.55572955 0.53558671\n",
      "  0.41929751]\n",
      " [0.04731715 0.04455732 0.04823714 0.04133735 0.04414585 0.05077855\n",
      "  0.03923396 0.05605467 0.32762299 0.3671905  0.58084727 0.59608488\n",
      "  0.40175368]] -> 1\n"
     ]
    }
   ],
   "source": [
    "dataX = []  # 입력으로 사용될 Sequence Data\n",
    "dataY = []  # 출력(타켓)으로 사용\n",
    "\n",
    "for i in range(0, len(y) - seq_length):\n",
    "    _x = x[i: i + seq_length]\n",
    "    _y = y[i + seq_length]  # 다음 나타날 주가(정답)\n",
    "    if i is 0:\n",
    "        print(_x, \"->\", _y)  # 첫번째 행만 출력해 봄\n",
    "    dataX.append(_x)  # dataX 리스트에 추가\n",
    "    dataY.append(_y)  # dataY 리스트에 추가\n",
    "\n",
    "# 학습용/테스트용 데이터 생성\n",
    "# 전체 70%를 학습용 데이터로 사용\n",
    "train_size = int(len(dataY) * 0.7)\n",
    "# 나머지(30%)를 테스트용 데이터로 사용\n",
    "test_size = len(dataY) - train_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1472, 28, 13)\n",
      "(1472, 1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 잘라 학습용 데이터 생성\n",
    "trainX = np.array(dataX[0:train_size])\n",
    "trainY = np.array(dataY[0:train_size])\n",
    "trainY = np.reshape(trainY, ((-1,1)))\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "# 데이터를 잘라 테스트용 데이터 생성\n",
    "testX = np.array(dataX[train_size:len(dataX)])\n",
    "testY = np.array(dataY[train_size:len(dataY)])\n",
    "testY = np.reshape(testY, ((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  Tensor(\"Placeholder:0\", shape=(?, 28, 13), dtype=float32)\n",
      "Y:  Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, seq_length, input_data_column_cnt])\n",
    "print(\"X: \", X)\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"Y: \", Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets:  Tensor(\"Placeholder_2:0\", shape=(?, 1), dtype=float32)\n",
      "predictions:  Tensor(\"Placeholder_3:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 검증용 측정지표를 산출하기 위한 targets, predictions를 생성한다\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"targets: \", targets)\n",
    "\n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델(LSTM 네트워크) 생성\n",
    "def lstm_cell():\n",
    "    # LSTM셀을 생성\n",
    "    # num_units: 각 Cell 출력 크기\n",
    "    # forget_bias:  to the biases of the forget gate\n",
    "    #              (default: 1)  in order to reduce the scale of forgetting in the beginning of the training.\n",
    "    # state_is_tuple: True ==> accepted and returned states are 2-tuples of the c_state and m_state.\n",
    "    # state_is_tuple: False ==> they are concatenated along the column axis.\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim,\n",
    "                                        forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
    "    if keep_prob < 1.0:\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    return cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-19-03d89dc4bdee>:10: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-20-54d5f027f0e9>:3: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\n",
    "stackedRNNs = [lstm_cell() for _ in range(num_stacked_layers)]\n",
    "multi_cells = tf.contrib.rnn.MultiRNNCell(stackedRNNs, state_is_tuple=True) if num_stacked_layers > 1 else lstm_cell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-099bcb7c33d7>:2: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000002B2BC981948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000002B2BC981948>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000002B2BC981948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000002B2BC981948>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From C:\\Users\\heon1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\heon1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BC97D0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BC97D0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BC97D0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BC97D0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BC9AFF08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BC9AFF08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BC9AFF08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BC9AFF08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BFF6D0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BFF6D0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BFF6D0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BFF6D0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BFF6D348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BFF6D348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BFF6D348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BFF6D348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BFF6D688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BFF6D688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BFF6D688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002B2BFF6D688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 28, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# RNN Cell(여기서는 LSTM셀임)들을 연결\n",
    "hypothesis, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
    "print(\"hypothesis: \", hypothesis)\n",
    "#tf.Session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(?, 20), dtype=float32)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis[:, -1])\n",
    "print(output_data_column_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002B2C04D5048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002B2C04D5048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002B2C04D5048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002B2C04D5048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "# [:, -1]를 잘 살펴보자. LSTM RNN의 마지막 (hidden)출력만을 사용했다.\n",
    "# 과거 여러 거래일의 주가를 이용해서 다음날의 주가 1개를 예측하기때문에 MANY-TO-ONE형태이다\n",
    "hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], output_data_column_cnt, activation_fn=tf.identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fully_connected/Identity:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"fully_connected/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "[[[0.03002188 0.03728953 0.03811752 ... 0.52590226 0.55338029 0.32982398]\n",
      "  [0.03655368 0.03811752 0.04271734 ... 0.60047049 0.58540873 0.3999993 ]\n",
      "  [0.03830152 0.03756553 0.03903751 ... 0.44426967 0.50889634 0.54034993]\n",
      "  ...\n",
      "  [0.05283695 0.04915699 0.05283695 ... 0.69309208 0.63345139 0.3280696 ]\n",
      "  [0.04823714 0.04731715 0.04915699 ... 0.55572955 0.53558671 0.41929751]\n",
      "  [0.04731715 0.04455732 0.04823714 ... 0.58084727 0.59608488 0.40175368]]\n",
      "\n",
      " [[0.03655368 0.03811752 0.04271734 ... 0.60047049 0.58540873 0.3999993 ]\n",
      "  [0.03830152 0.03756553 0.03903751 ... 0.44426967 0.50889634 0.54034993]\n",
      "  [0.03710567 0.03756553 0.03876151 ... 0.30533728 0.43861171 0.62280592]\n",
      "  ...\n",
      "  [0.04823714 0.04731715 0.04915699 ... 0.55572955 0.53558671 0.41929751]\n",
      "  [0.04731715 0.04455732 0.04823714 ... 0.58084727 0.59608488 0.40175368]\n",
      "  [0.04547717 0.05237695 0.05421679 ... 0.54788026 0.49466148 0.46842023]]\n",
      "\n",
      " [[0.03830152 0.03756553 0.03903751 ... 0.44426967 0.50889634 0.54034993]\n",
      "  [0.03710567 0.03756553 0.03876151 ... 0.30533728 0.43861171 0.62280592]\n",
      "  [0.03636967 0.03535769 0.03793352 ... 0.47645175 0.36921675 0.47543776]\n",
      "  ...\n",
      "  [0.04731715 0.04455732 0.04823714 ... 0.58084727 0.59608488 0.40175368]\n",
      "  [0.04547717 0.05237695 0.05421679 ... 0.54788026 0.49466148 0.46842023]\n",
      "  [0.05283695 0.05789663 0.05881662 ... 0.58398698 0.62989268 0.38771862]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.68972253 0.68972253 0.69339024 ... 0.49215032 0.57206355 0.42631504]\n",
      "  [0.69216676 0.69828007 0.70561549 ... 0.47017232 0.52313121 0.49298159]\n",
      "  [0.69339024 0.70194778 0.70683761 ... 0.61381427 0.62188557 0.22631539]\n",
      "  ...\n",
      "  [0.40426573 0.39142942 0.41649098 ... 0.54003097 0.50355827 0.34561343]\n",
      "  [0.39081836 0.37553782 0.39570819 ... 0.48744075 0.54982157 0.46315708]\n",
      "  [0.37920553 0.35658821 0.37920553 ... 0.46860246 0.42704588 0.40350806]]\n",
      "\n",
      " [[0.69216676 0.69828007 0.70561549 ... 0.47017232 0.52313121 0.49298159]\n",
      "  [0.69339024 0.70194778 0.70683761 ... 0.61381427 0.62188557 0.22631539]\n",
      "  [0.71172743 0.69950218 0.71294955 ... 0.56043912 0.51156538 0.34736781]\n",
      "  ...\n",
      "  [0.39081836 0.37553782 0.39570819 ... 0.48744075 0.54982157 0.46315708]\n",
      "  [0.37920553 0.35658821 0.37920553 ... 0.46860246 0.42704588 0.40350806]\n",
      "  [0.35658821 0.37798206 0.38042765 ... 0.46938739 0.57562226 0.40701683]]\n",
      "\n",
      " [[0.69339024 0.70194778 0.70683761 ... 0.61381427 0.62188557 0.22631539]\n",
      "  [0.71172743 0.69950218 0.71294955 ... 0.56043912 0.51156538 0.34736781]\n",
      "  [0.7092832  0.70683761 0.7092832  ... 0.46860246 0.62099589 0.57719197]\n",
      "  ...\n",
      "  [0.37920553 0.35658821 0.37920553 ... 0.46860246 0.42704588 0.40350806]\n",
      "  [0.35658821 0.37798206 0.38042765 ... 0.46938739 0.57562226 0.40701683]\n",
      "  [0.37798206 0.39020731 0.39754273 ... 0.52276254 0.54537318 0.37017479]]]\n",
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print(Y)\n",
    "print(hypothesis)\n",
    "print(trainX)\n",
    "print(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\heon1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# [:, -1]를 잘 살펴보자. LSTM RNN의 마지막 (hidden)출력만을 사용했다.\n",
    "# 과거 여러 거래일의 주가를 이용해서 다음날의 주가 1개를 예측하기때문에 MANY-TO-ONE형태이다\n",
    "#hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], output_data_column_cnt, activation_fn=tf.identity)\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=hypothesis))\n",
    "\n",
    "# 최적화함수로 AdamOptimizer를 사용한다\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "# optimizer = tf.train.RMSPropOptimizer(learning_rate) # LSTM과 궁합 별로임\n",
    "#correct_pred = tf.equal(tf.round(tf.nn.sigmoid(hypothesis)), Y)\n",
    "accr = tf.reduce_mean(tf.cast(tf.equal(tf.round(tf.nn.sigmoid(hypothesis)), Y), tf.float32))\n",
    "\n",
    "train = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error_summary = []  # 학습용 데이터의 오류를 중간 중간 기록한다\n",
    "test_error_summary = []  # 테스트용 데이터의 오류를 중간 중간 기록한다\n",
    "train_accr_summary = []\n",
    "test_accr_summary = []\n",
    "test_predict = ''  # 테스트용데이터로 예측한 결과\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "import  datetime\n",
    "start_time = datetime.datetime.now()  # 시작시간을 기록한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습을 시작합니다...\n",
      "epoch: 100, train_accr(A): 0.536005437374115, test_accr(B): 0.5189873576164246\n",
      "epoch: 200, train_accr(A): 0.536005437374115, test_accr(B): 0.5189873576164246\n",
      "epoch: 300, train_accr(A): 0.536005437374115, test_accr(B): 0.5189873576164246\n",
      "epoch: 400, train_accr(A): 0.5557065010070801, test_accr(B): 0.4920886158943176\n",
      "epoch: 500, train_accr(A): 0.557744562625885, test_accr(B): 0.4762658178806305\n",
      "epoch: 600, train_accr(A): 0.5618206262588501, test_accr(B): 0.4810126721858978\n",
      "epoch: 700, train_accr(A): 0.579483687877655, test_accr(B): 0.4873417615890503\n",
      "epoch: 800, train_accr(A): 0.579483687877655, test_accr(B): 0.48417720198631287\n",
      "epoch: 900, train_accr(A): 0.5896739363670349, test_accr(B): 0.5221518874168396\n",
      "epoch: 1000, train_accr(A): 0.5869565010070801, test_accr(B): 0.5427215099334717\n"
     ]
    }
   ],
   "source": [
    "print('학습을 시작합니다...')\n",
    "for epoch in range(epoch_num):\n",
    "    _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
    "    if ((epoch + 1) % 100 == 0) or (epoch == epoch_num - 1):  # 100번째마다 또는 마지막 epoch인 경우\n",
    "        # 학습용데이터로 accr오차를 구한다\n",
    "#        train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
    "#        train_error = sess.run(loss, feed_dict={X: trainY, Y: train_predict})\n",
    "        train_acc = sess.run(accr,feed_dict={X: trainX, Y: trainY})\n",
    "#        train_error_summary.append(train_error)\n",
    "        train_accr_summary.append(train_acc)\n",
    "        \n",
    "                # 테스트용데이터로 rmse오차를 구한다\n",
    "#        test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
    "#        test_error = sess.run(loss, feed_dict={X: testY, Y: test_predict})\n",
    "        test_acc = sess.run(accr,feed_dict={X: testX, Y: testY})        \n",
    "#        test_error_summary.append(test_error)\n",
    "        test_accr_summary.append(test_acc)\n",
    "\n",
    "        # 현재 오류를 출력한다\n",
    "        print(\"epoch: {}, train_accr(A): {}, test_accr(B): {}\".format(epoch + 1, train_acc, \n",
    "                                                                      test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Root Mean Square Error')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 결과 그래프 출력\n",
    "plt.figure(1)\n",
    "plt.plot(train_accr_summary, 'gold')\n",
    "plt.plot(test_accr_summary, 'b')\n",
    "plt.xlabel('Epoch(x100)')\n",
    "plt.ylabel('Root Mean Square Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent_data.shape: (1, 28, 13)\n",
      "recent_data: [[[ 3.40149514e-01  3.59202559e-01  3.65326752e-01  3.37427650e-01\n",
      "    3.59202559e-01  3.60832073e-01  5.17721435e-02  4.63628825e-02\n",
      "   -5.66000000e-02  1.30000000e-03  4.00000000e-03  1.00000000e-04\n",
      "    2.20000000e-03]\n",
      "  [ 3.62604888e-01  3.57161161e-01  3.62604888e-01  3.55800229e-01\n",
      "    3.57161161e-01  3.66527754e-01  1.12904521e-02  4.79784845e-02\n",
      "   -2.07000000e-02  1.60000000e-03 -1.10000000e-03  4.10000000e-03\n",
      "    3.50000000e-03]\n",
      "  [ 3.57841627e-01  3.51036968e-01  3.61243956e-01  3.48995570e-01\n",
      "    3.51036968e-01  3.72515522e-01  2.12294026e-02  4.40339556e-02\n",
      "    3.00000000e-04 -6.30000000e-03  7.00000000e-04  4.60000000e-03\n",
      "    3.00000000e-03]\n",
      "  [ 3.52397900e-01  3.51717434e-01  3.55800229e-01  3.50356502e-01\n",
      "    3.51717434e-01  3.76166600e-01  1.29542610e-02  3.80995616e-02\n",
      "   -7.00000000e-04  5.90000000e-03 -8.00000000e-03  5.40000000e-03\n",
      "   -1.00000000e-03]\n",
      "  [ 3.50356502e-01  3.41510446e-01  3.51036968e-01  3.40829980e-01\n",
      "    3.41510446e-01  3.76458686e-01  2.01428132e-02  3.93154104e-02\n",
      "    9.50000000e-03  1.08000000e-02 -6.00000000e-04  1.00000000e-04\n",
      "    8.00000000e-04]\n",
      "  [ 3.36747185e-01  3.40149514e-01  3.42190912e-01  3.34025321e-01\n",
      "    3.40149514e-01  3.72369479e-01  1.42888003e-02  2.41156824e-02\n",
      "   -2.30000000e-02  5.70000000e-03 -1.46000000e-02  4.50000000e-03\n",
      "    4.00000000e-04]\n",
      "  [ 3.40149514e-01  3.32664389e-01  3.43551843e-01  3.32664389e-01\n",
      "    3.32664389e-01  3.67111926e-01  1.57031625e-02  2.59050639e-02\n",
      "   -1.40000000e-02 -1.81000000e-02  1.05000000e-02 -1.32000000e-02\n",
      "    3.60000000e-03]\n",
      "  [ 3.34025321e-01  3.31303458e-01  3.39469048e-01  3.29942526e-01\n",
      "    3.31303458e-01  3.62876676e-01  1.24324187e-02  2.23378324e-02\n",
      "   -1.40000000e-03  1.90000000e-03 -5.80000000e-03  5.00000000e-04\n",
      "    5.00000000e-04]\n",
      "  [ 3.33344855e-01  3.28581594e-01  3.34025321e-01  3.27220662e-01\n",
      "    3.28581594e-01  3.57911210e-01  1.23655670e-02  2.20991133e-02\n",
      "   -8.90000000e-03 -5.80000000e-03 -1.13000000e-02 -1.19000000e-02\n",
      "    2.10000000e-03]\n",
      "  [ 3.29942526e-01  3.24498799e-01  3.30622992e-01  3.22457401e-01\n",
      "    3.24498799e-01  3.54260132e-01  1.24927848e-02  1.89969794e-02\n",
      "   -3.29000000e-02 -2.22000000e-02  7.50000000e-03  6.40000000e-03\n",
      "   -3.20000000e-03]\n",
      "  [ 3.28581594e-01  3.41510446e-01  3.41510446e-01  3.25859730e-01\n",
      "    3.41510446e-01  3.54552219e-01  1.69793314e-02  2.00880064e-02\n",
      "   -8.30000000e-03  1.09000000e-02 -1.13000000e-02  4.50000000e-03\n",
      "    3.60000000e-03]\n",
      "  [ 3.36066719e-01  3.36747185e-01  3.40829980e-01  3.35386253e-01\n",
      "    3.36747185e-01  3.55428477e-01  1.52990590e-02  1.99241399e-02\n",
      "   -1.83000000e-02  1.27000000e-02 -1.56000000e-02 -1.95000000e-02\n",
      "    1.70000000e-03]\n",
      "  [ 3.31303458e-01  3.46954173e-01  3.48315105e-01  3.31303458e-01\n",
      "    3.46954173e-01  3.58787469e-01  2.48932743e-02  2.49770941e-02\n",
      "   -1.10000000e-03 -5.60000000e-03 -3.30000000e-03  5.00000000e-04\n",
      "    4.30000000e-03]\n",
      "  [ 3.47634639e-01  3.47634639e-01  3.51036968e-01  3.41510446e-01\n",
      "    3.47634639e-01  3.62876676e-01  2.38565742e-02  2.96367687e-02\n",
      "   -2.30000000e-03 -3.00000000e-04 -1.67000000e-02  1.21000000e-02\n",
      "    2.20000000e-03]\n",
      "  [ 3.41510446e-01  3.45593241e-01  3.47634639e-01  3.39469048e-01\n",
      "    3.45593241e-01  3.67404013e-01  2.26751951e-02  3.37657992e-02\n",
      "    1.83000000e-02 -7.90000000e-03  6.00000000e-03 -8.80000000e-03\n",
      "   -6.70000000e-03]\n",
      "  [ 3.46954173e-01  3.38788582e-01  3.48315105e-01  3.38788582e-01\n",
      "    3.38788582e-01  3.66819840e-01  1.17165069e-02  3.16316913e-02\n",
      "    2.15000000e-02 -8.10000000e-03  1.34000000e-02  8.10000000e-03\n",
      "   -5.90000000e-03]\n",
      "  [ 3.40829980e-01  3.44912775e-01  3.46273707e-01  3.40829980e-01\n",
      "    3.44912775e-01  3.68572358e-01  1.08589095e-02  2.98311831e-02\n",
      "   -2.03000000e-02  6.00000000e-03 -1.00000000e-03  1.11000000e-02\n",
      "    1.00000000e-03]\n",
      "  [ 3.46273707e-01  3.46954173e-01  3.48995570e-01  3.44912775e-01\n",
      "    3.46954173e-01  3.68572358e-01  8.40635051e-03  2.31456334e-02\n",
      "   -1.46000000e-02 -9.40000000e-03  1.24000000e-02  4.00000000e-04\n",
      "    2.00000000e-04]\n",
      "  [ 3.49676036e-01  3.57161161e-01  3.62604888e-01  3.48315105e-01\n",
      "    3.57161161e-01  3.70616961e-01  2.73932281e-02  2.45797685e-02\n",
      "    1.04000000e-02  7.10000000e-03 -3.00000000e-03  7.10000000e-03\n",
      "    1.40000000e-03]\n",
      "  [ 3.58522093e-01  3.63285354e-01  3.70770479e-01  3.58522093e-01\n",
      "    3.63285354e-01  3.74414082e-01  3.01605887e-02  2.76151420e-02\n",
      "    1.07000000e-02  2.90000000e-03  4.00000000e-03 -2.30000000e-03\n",
      "   -6.30000000e-03]\n",
      "  [ 3.68048615e-01  3.53078366e-01  3.68048615e-01  3.51717434e-01\n",
      "    3.53078366e-01  3.77480988e-01  2.07330038e-02  3.12713874e-02\n",
      "   -2.80000000e-03 -2.80000000e-03 -8.30000000e-03 -8.30000000e-03\n",
      "   -1.00000000e-04]\n",
      "  [ 3.55800229e-01  3.55119763e-01  3.59202559e-01  3.50356502e-01\n",
      "    3.55119763e-01  3.79671634e-01  9.84066848e-03  3.08584843e-02\n",
      "   -8.70000000e-03 -4.00000000e-03  9.10000000e-03  2.00000000e-03\n",
      "   -5.40000000e-03]\n",
      "  [ 3.57161161e-01  3.61243956e-01  3.69409547e-01  3.55119763e-01\n",
      "    3.61243956e-01  3.82738540e-01  2.60003183e-02  3.79929473e-02\n",
      "    1.59000000e-02 -4.00000000e-04 -7.20000000e-03  1.16000000e-02\n",
      "    5.00000000e-04]\n",
      "  [ 3.69409547e-01  3.89143057e-01  3.89823523e-01  3.68048615e-01\n",
      "    3.89143057e-01  3.89602566e-01  6.48396532e-02  5.31777047e-02\n",
      "    2.94000000e-02  4.90000000e-03  1.90000000e-03 -3.90000000e-03\n",
      "   -2.80000000e-03]\n",
      "  [ 3.68048615e-01  3.53078366e-01  3.68048615e-01  3.51717434e-01\n",
      "    3.53078366e-01  3.77480988e-01  2.07330038e-02  3.12713874e-02\n",
      "   -2.80000000e-03 -2.80000000e-03 -8.30000000e-03 -8.30000000e-03\n",
      "   -1.00000000e-04]\n",
      "  [ 3.55800229e-01  3.55119763e-01  3.59202559e-01  3.50356502e-01\n",
      "    3.55119763e-01  3.79671634e-01  9.84066848e-03  3.08584843e-02\n",
      "   -8.70000000e-03 -4.00000000e-03  9.10000000e-03  2.00000000e-03\n",
      "   -5.40000000e-03]\n",
      "  [ 3.57161161e-01  3.61243956e-01  3.69409547e-01  3.55119763e-01\n",
      "    3.61243956e-01  3.82738540e-01  2.60003183e-02  3.79929473e-02\n",
      "    1.59000000e-02 -4.00000000e-04 -7.20000000e-03  1.16000000e-02\n",
      "    5.00000000e-04]\n",
      "  [ 3.69409547e-01  3.89143057e-01  3.89823523e-01  3.68048615e-01\n",
      "    3.89143057e-01  3.89602566e-01  6.48396532e-02  5.31777047e-02\n",
      "    2.94000000e-02  4.90000000e-03  1.90000000e-03 -3.90000000e-03\n",
      "   -2.80000000e-03]]]\n"
     ]
    }
   ],
   "source": [
    "recent_data = np.array([x[len(x) - seq_length:]])\n",
    "print(\"recent_data.shape:\", recent_data.shape)\n",
    "print(\"recent_data:\", recent_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_predict [0.15958965]\n"
     ]
    }
   ],
   "source": [
    "# 내일 종가를 예측해본다\n",
    "test_predict = sess.run(hypothesis, feed_dict={X: recent_data})\n",
    "\n",
    "print(\"test_predict\", test_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('학습을 시작합니다...')\n",
    "for epoch in range(epoch_num):\n",
    "    _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
    "    if ((epoch + 1) % 100 == 0) or (epoch == epoch_num - 1):  # 100번째마다 또는 마지막 epoch인 경우\n",
    "        # 학습용데이터로 accr오차를 구한다\n",
    "        train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
    "#        train_error = sess.run(loss, feed_dict={X: trainY, Y: train_predict})\n",
    "        train_acc = sess.run(accr,feed_dict={X: trainX, Y: trainY})\n",
    "#        train_error_summary.append(train_error)\n",
    "        train_accr_summary.append(train__acc)\n",
    "        print(train_acc)\n",
    "\n",
    "        # 테스트용데이터로 rmse오차를 구한다\n",
    "        test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
    "#        test_error = sess.run(loss, feed_dict={X: testY, Y: test_predict})\n",
    "        test_acc = sess.run(accr,feed_dict={targets: testY, predictions: trest_predict})        \n",
    "#        test_error_summary.append(test_error)\n",
    "        test_accr_summary.append(test_error)\n",
    "\n",
    "        # 현재 오류를 출력한다\n",
    "        print(\"epoch: {}, train_accr(A): {}, test_accr(B): {}\".format(epoch + 1, train_acc, \n",
    "                                                                      test_acc))\n",
    "\n",
    "end_time = datetime.datetime.now()  # 종료시간을 기록한다\n",
    "elapsed_time = end_time - start_time  # 경과시간을 구한다\n",
    "print('elapsed_time:', elapsed_time)\n",
    "print('elapsed_time per epoch:', elapsed_time / epoch_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
