{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ‘Š14. ìˆœí™˜ ì‹ ê²½ë§ (RNN, Recurrent Neural Network) - (3)\n",
    "\n",
    "ì €ë²ˆ í¬ìŠ¤íŒ…ì¸ [07-2. ìˆœí™˜ ì‹ ê²½ë§(RNN) - (2)](http://excelsior-cjh.tistory.com/184)ì—ì„œëŠ” RNNì„ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì¸ BPTTì™€ í…ì„œí”Œë¡œë¥¼ ì´ìš©í•´ MNIST ë¶„ë¥˜ê¸°ì™€ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•˜ëŠ” RNN ëª¨ë¸ì„ êµ¬í˜„í•´ ë³´ì•˜ë‹¤. ê·¸ë¦¬ê³  ì‹¬ì¸µ RNNì„ êµ¬í˜„í•˜ëŠ” ë°©ë²•ê³¼ RNNì— ë“œë¡­ì•„ì›ƒì„ ì ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³´ì•˜ë‹¤. \n",
    "\n",
    "ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” RNNì˜ ë³€í˜•ì´ë¼ê³  í•  ìˆ˜ ìˆëŠ” LSTMê³¼ LSTMì˜ ë³€í˜•ì¸ GRUì— ëŒ€í•´ ì•Œì•„ë³´ë„ë¡ í•˜ì."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‘Š14.1. RNN Cellì˜ ë¬¸ì œì "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ‘Š14.1.1 BPTTì˜ ë¬¸ì œì \n",
    "### ğŸ‘Š14.1.2 ì¥ê¸° ì˜ì¡´ì„±(Long-Term Dependency) ë¬¸ì œ\n",
    "[ì €ë²ˆ í¬ìŠ¤íŒ…](http://excelsior-cjh.tistory.com/184)ì—ì„œ ì‚´í´ë³¸ BPTTëŠ” RNNì—ì„œì˜ ì—­ì „íŒŒ ë°©ë²•ì¸ BPTT(BackPropagation Through Time)ì€ ì•„ë˜ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ ëª¨ë“  íƒ€ì„ìŠ¤í…ë§ˆë‹¤ ì²˜ìŒë¶€í„° ëê¹Œì§€ ì—­ì „íŒŒí•œë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "![](./images/rnn08.png)\n",
    "\n",
    "\n",
    "\n",
    "ê·¸ë ‡ê¸° ë•Œë¬¸ì— íƒ€ì„ ìŠ¤í…ì´ í´ ê²½ìš°, ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ RNNì„ í¼ì¹˜ê²Œ(unfold)ë˜ë©´ ë§¤ìš° ê¹Šì€ ë„¤íŠ¸ì›Œí¬ê°€ ë ê²ƒì´ë‹¤.\n",
    "\n",
    "RNNì€ ì´ë¡ ì ìœ¼ë¡œ ëª¨ë“  ì´ì „ íƒ€ì„ ìŠ¤í…ì´ ì˜í–¥ì„ ì£¼ì§€ë§Œ ì•ìª½ì˜ íƒ€ì„ ìŠ¤í…(ì˜ˆë¥¼ ë“¤ì–´ $t=0, t=1$)ì€ íƒ€ì„ ìŠ¤í…ì´ ê¸¸ì–´ì§ˆ ìˆ˜ë¡ ì „íŒŒ ê³¼ì •ì—ì„œ ì ì°¨ ì˜í–¥ë ¥ì´ ì¤„ì–´ë“ ë‹¤.\n",
    "\n",
    "ì´ë¥¼ **ì¥ê¸° ì˜ì¡´ì„±(Long-Term Dependency) ë¬¸ì œ**ë¼ê³  í•œë‹¤. ì´ëŸ¬í•œ ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” ì´ìœ ëŠ” ì…ë ¥ ë°ì´í„°ê°€ RNN Cellì„ ê±°ì¹˜ë©´ì„œ íŠ¹ì • ì—°ì‚°ì„ í†µí•´ ë°ì´í„°ê°€ ë³€í™˜ë˜ì–´, ì¼ë¶€ ì •ë³´ëŠ” íƒ€ì„ ìŠ¤í…ë§ˆë‹¤ ì‚¬ë¼ì§€ê¸° ë•Œë¬¸ì´ë‹¤.\n",
    "\n",
    "ì´ëŸ¬í•œ ë„¤íŠ¸ì›Œí¬ëŠ” [05-1. ì‹¬ì¸µ ì‹ ê²½ë§ í•™ìŠµ](http://excelsior-cjh.tistory.com/177?category=940400)ì—ì„œ ì‚´í´ë³¸ **ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤ ë° í­ì£¼**(vanishing & exploding gradient) ë¬¸ì œê°€ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ í¬ë‹¤. ê·¸ë¦¬ê³ , ê³„ì‚°ëŸ‰ ë˜í•œ ë§ê¸° ë•Œë¬¸ì— í•œë²ˆ í•™ìŠµí•˜ëŠ”ë° ì•„ì£¼ ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦¬ëŠ” ë¬¸ì œê°€ ìˆë‹¤. \n",
    "\n",
    "ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì¥ê¸°ê°„ì˜ ë©”ëª¨ë¦¬ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ì…€ì´ ë§Œë“¤ì–´ì¡ŒëŠ”ë°, ê·¸ ì¤‘ì—ì„œ ëŒ€í‘œì ì¸ ì…€ë“¤ì´ LSTMê³¼ GRU ì…€ì´ë‹¤. ë¨¼ì €, LSTM ì…€ì— ëŒ€í•´ ì•Œì•„ë³´ë„ë¡ í•˜ì."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‘Š14.2. LSTM Cell\n",
    "\n",
    "[**LSTM**(Long Short-Term Memory) ì…€](https://www.mitpressjournals.org/doi/abs/10.1162/neco.1997.9.8.1735#.WIxuWvErJnw)ì€ S.Hochreiterì™€ J.Schmidhuberê°€ 1997ë…„ì— ì œì•ˆí•œ ì…€ë¡œì¨, RNN ì…€ì˜ ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œë¥¼ í•´ê²°í•  ë¿ë§Œ ì•„ë‹ˆë¼ í•™ìŠµ ë˜í•œ ë¹ ë¥´ê²Œ ìˆ˜ë ´í•œë‹¤. LSTM ì…€ì˜ êµ¬ì¡°ëŠ” ì•„ë˜ì˜ ê·¸ë¦¼(ì› ì¶œì²˜: [colah's blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/))ê³¼ ê°™ë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "![LSTM](./images/lstm.PNG)\n",
    "\n",
    "\n",
    "\n",
    "ìœ„ì˜ ê·¸ë¦¼ì—ì„œ ë³´ë©´ LSTM ì…€ì—ì„œëŠ” ìƒíƒœ(state)ê°€ ë‘ ê°œì˜ ë²¡í„° $\\mathbf{h}_t$ì™€ $\\mathbf{c}_t$ë¡œ ë‚˜ëˆ„ì–´ ì§„ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. $\\mathbf{h}_t$ë¥¼ ë‹¨ê¸° ìƒíƒœ(short-term state), $\\mathbf{c}_t$ë¥¼ ì¥ê¸° ìƒíƒœ(long-term state)ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. \n",
    "\n",
    "ìœ„ì˜ LSTM ì…€ì„ ìì„¸íˆ ì‚´í´ë³´ë„ë¡ í•˜ì. LSTMì˜ í•µì‹¬ì€ ë„¤íŠ¸ì›Œí¬ê°€ ì¥ê¸° ìƒíƒœ($\\mathbf{c}_t$)ì—ì„œ ê¸°ì–µí•  ë¶€ë¶„, ì‚­ì œí•  ë¶€ë¶„,  ê·¸ë¦¬ê³  ì½ì–´ ë“¤ì¼ ë¶€ë¶„ì„ í•™ìŠµí•˜ëŠ” ê²ƒì´ë‹¤. ì¥ê¸° ê¸°ì–µ $\\mathbf{c}_{t-1}$ì€ ì…€ì˜ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ í†µê³¼í•˜ê²Œ ë˜ëŠ”ë° **forget gate**ë¥¼ ì§€ë‚˜ë©´ì„œ ì¼ë¶€ë¥¼ ê¸°ì–µ(ì •ë³´)ì„ ìƒê³ , ê·¸ ë‹¤ìŒ ë§ì…ˆ(+) ì—°ì‚°ìœ¼ë¡œ **input gate**ë¡œ ë¶€í„° ìƒˆë¡œìš´ ê¸°ì–µ ì¼ë¶€ë¥¼ ì¶”ê°€í•œë‹¤. ì´ë ‡ê²Œ ë§Œë“¤ì–´ì§„ $\\mathbf{c}_t$ëŠ” ë³„ë„ì˜ ì¶”ê°€ ì—°ì‚° ì—†ì´ ë°”ë¡œ ì¶œë ¥ë˜ë©°, ì´ëŸ¬í•œ ì¥ê¸° ê¸°ì–µ $\\mathbf{c}_t$ëŠ” íƒ€ì„ ìŠ¤í…ë§ˆë‹¤ ì¼ë¶€ì˜ ê¸°ì–µì„ ì‚­ì œí•˜ê³  ì¶”ê°€í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹˜ê²Œ ëœë‹¤. ê·¸ë¦¬ê³  ë§ì…ˆ ì—°ì‚° í›„ì— $\\mathbf{c}_t$ëŠ” ë³µì‚¬ë˜ì–´ **output gate**ì˜ $\\tanh$í•¨ìˆ˜ë¡œ ì „ë‹¬ë˜ì–´ ë‹¨ê¸° ìƒíƒœ $\\mathbf{h}_{t}$ì™€ ì…€ì˜ ì¶œë ¥ì¸ $\\mathbf{y}_t$ë¥¼ ë§Œë“ ë‹¤. ì´ë²ˆì—ëŠ” ìœ„ì—ì„œ ì„¤ëª…í•œ forget, input, output ê²Œì´íŠ¸(gate)ê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ì— ëŒ€í•´ ì•Œì•„ë³´ë„ë¡ í•˜ì. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¨¼ì €, í˜„ì¬ ì…ë ¥ ë²¡í„° $\\mathbf{x}_{t}$ì™€ ì´ì „ì˜ ë‹¨ê¸° ìƒíƒœ $\\mathbf{h}_{t-1}$ì´ **ë„¤ ê°œì˜ ë‹¤ë¥¸ FC-ë ˆì´ì–´(Fully-Connected layer)ì— ì£¼ì…**ë˜ëŠ”ë°, ì´ ë ˆì´ì–´ëŠ” ëª¨ë‘ ë‹¤ìŒê³¼ ê°™ì´ ë‹¤ë¥¸ ëª©ì ì„ ê°€ì§„ë‹¤.\n",
    "\n",
    "- ì£¼ìš” ë ˆì´ì–´ëŠ” $\\mathbf{g}_tâ€‹$ë¥¼ ì¶œë ¥í•˜ëŠ” ë ˆì´ì–´ì´ë©°, í˜„ì¬ ì…ë ¥ ë°ì´í„° $\\mathbf{x}_tâ€‹$ì™€ ì´ì „ íƒ€ì„ìŠ¤í…ì˜ ë‹¨ê¸° ìƒíƒœ $\\mathbf{h}_{t-1}â€‹$ì„ ë¶„ì„í•˜ëŠ” ì—­í• ì„ í•œë‹¤. LSTM ì…€ì—ì„œëŠ” ì´ ë ˆì´ì–´ì˜ ì¶œë ¥ì¸ $\\mathbf{g}_{t}â€‹$ê°€ $\\mathbf{i}_{t}â€‹$ì˜ ê³±ì…ˆ($\\timesâ€‹$)ì—°ì‚° í›„ ì¥ê¸° ìƒíƒœ $\\mathbf{c}_{t}â€‹$ì— ì¼ë¶€ë¶„ì´ ë”í•´ì§€ê²Œ ëœë‹¤. ë°˜ë©´ì—, [ê¸°ë³¸ RNN ì…€](http://excelsior-cjh.tistory.com/183)ì—ì„œëŠ” ì´ ë ˆì´ì–´ë§Œ ìˆìœ¼ë©°, ë°”ë¡œ $\\mathbf{y}_{t}â€‹$ì™€ $\\mathbf{h}_{t}â€‹$ë¡œ ì¶œë ¥ëœë‹¤. \n",
    "\n",
    "- $\\mathbf{f}_{t}, \\mathbf{i}_{t}, \\mathbf{o}_{t}$ë¥¼ ì¶œë ¥í•˜ëŠ” ì„¸ ê°œì˜ ë ˆì´ì–´ì—ì„œëŠ” í™œì„±í™” í•¨ìˆ˜ë¡œ ì‹œê·¸ëª¨ì´ë“œ(sigmoid, logistic)ë¥¼ ì‚¬ìš©í•œë‹¤. ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì˜ ì¶œë ¥ì˜ ë²”ìœ„ëŠ” 0 ~ 1 ì´ë©°, ì´ ì¶œë ¥ê°’ì€ ê° forget, input, output ê²Œì´íŠ¸ì˜ ì›ì†Œë³„(element-wise) ê³±ì…ˆì—°ì‚°ì— ì…ë ¥ëœë‹¤. ë”°ë¼ì„œ, ì¶œë ¥ì´ `0`ì¼ ê²½ìš°ì—ëŠ” ê²Œì´íŠ¸ë¥¼ ë‹«ê³  `1`ì¼ ê²½ìš°ì—ëŠ” ê²Œì´íŠ¸ë¥¼ ì—´ê¸° ë•Œë¬¸ì—  $\\mathbf{f}_{t}, \\mathbf{i}_{t}, \\mathbf{o}_{t}$ë¥¼ **gate controller**ë¼ê³  í•œë‹¤.\n",
    "  - **Forget gate** : $\\mathbf{f}_{t}$ì— ì˜í•´ ì œì–´ë˜ë©° ì¥ê¸° ìƒíƒœ $\\mathbf{c}_{t}$ì˜ ì–´ëŠ ë¶€ë¶„ì„ ì‚­ì œí• ì§€ ì œì–´í•œë‹¤.\n",
    "  - **Input gate** : $\\mathbf{i}_{t}$ì— ì˜í•´ ì œì–´ë˜ë©° $\\mathbf{g}_{t}$ì˜ ì–´ëŠ ë¶€ë¶„ì´ ì¥ê¸° ìƒíƒœ $\\mathbf{c}_{t}$ì— ë”í•´ì ¸ì•¼ í•˜ëŠ”ì§€ ì œì–´í•œë‹¤.\n",
    "  - **Output gate** : $\\mathbf{o}_{t}$ëŠ” ì¥ê¸° ìƒíƒœ $\\mathbf{c}_{t}$ì˜ ì–´ëŠ ë¶€ë¶„ì„ ì½ì–´ì„œ $\\mathbf{h}_{t}$ ì™€ $\\mathbf{y}_{t}$ë¡œ ì¶œë ¥í•´ì•¼ í•˜ëŠ”ì§€ ì œì–´í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒì˜ ì‹ì€ ìœ„ì˜ ê·¸ë¦¼ì—ì„œ íƒ€ì„ ìŠ¤í… $t$ì—ì„œ, ì…€ì˜ ì¥ê¸° ìƒíƒœ, ë‹¨ê¸° ìƒíƒœ, ê·¸ë¦¬ê³  ê° ë ˆì´ì–´ì˜ ì¶œë ¥ì„ êµ¬í•˜ëŠ” ì‹ì„ ë‚˜íƒ€ë‚¸ ê²ƒì´ë‹¤.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "\\mathbf{f}_{t} & = & \\sigma \\left( \\mathbf{W}_{xf}^{T} \\cdot \\mathbf{x}_{t} + \\mathbf{W}_{hf}^{T} \\cdot \\mathbf{h}_{t-1} + \\mathbf{b}_{f} \\right) \\\\ \\mathbf{i}_{t} & =  & \\sigma \\left( \\mathbf{W}_{xi}^{T} \\cdot \\mathbf{x}_{t} + \\mathbf{W}_{hi}^{T} \\cdot \\mathbf{h}_{t-1} + \\mathbf{b}_{i} \\right) \\\\ \\mathbf{o}_{t} & = & \\sigma \\left( \\mathbf{W}_{xo}^{T} \\cdot \\mathbf{x}_{t} + \\mathbf{W}_{ho}^{T} \\cdot \\mathbf{h}_{t-1} + \\mathbf{b}_{o} \\right) \\\\ \\mathbf{g}_{t} & = & \\tanh \\left( \\mathbf{W}_{xg}^{T} \\cdot \\mathbf{x}_{t} + \\mathbf{W}_{hg}^{T} \\cdot \\mathbf{h}_{t-1} + \\mathbf{b}_{g} \\right) \\\\ \\mathbf{c}_{t} & = & \\mathbf{f}_{t} \\otimes \\mathbf{c}_{t-1} + \\mathbf{i}_{t} \\otimes \\mathbf{g}_{t} \\\\ \\mathbf{y}_{t}, \\mathbf{h}_{t} & = & \\mathbf{o}_{t} \\otimes \\tanh \\left( \\mathbf{c}_{t} \\right) \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "\n",
    "- $\\mathbf{W}_{xf}, \\mathbf{W}_{xi}, \\mathbf{W}_{xo}, \\mathbf{W}_{xg}$ : ì…ë ¥ ë²¡í„° $\\mathbf{x}_{t}$ì— ì—°ê²°ëœ ë„¤ ê°œì˜ ë ˆì´ì–´ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ í–‰ë ¬\n",
    "- $\\mathbf{W}_{hf}, \\mathbf{W}_{hi}, \\mathbf{W}_{ho}, \\mathbf{W}_{hg}$ : ì´ì „ íƒ€ì„ìŠ¤í…ì˜ ë‹¨ê¸° ìƒíƒœ $\\mathbf{h}_{t-1}$ì— ì—°ê²°ëœ ë„¤ ê°œì˜ ë ˆì´ì–´ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ í–‰ë ¬\n",
    "- $\\mathbf{b}_{f}, \\mathbf{b}_{i}, \\mathbf{b}_{o}, \\mathbf{b}_{g}$ : ë„¤ ê°œì˜ ë ˆì´ì–´ì— ëŒ€í•œ í¸í–¥(bias), [í…ì„œí”Œë¡œ](https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/LSTMCell)(TensorFlow)ì—ì„œëŠ” $\\mathbf{b}_{f}$ ë¥¼ `1`ë¡œ ì´ˆê¸°í™”í•˜ì—¬ í•™ìŠµ ì‹œì‘ì‹œì— ëª¨ë“ ê²ƒì„ ìƒì–´ë²„ë¦¬ëŠ” ê²ƒì„ ë°©ì§€í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ‘Š14.2.1 í…ì„œí”Œë¡œì—ì„œì˜ LSTM ì…€\n",
    "\n",
    "í…ì„œí”Œë¡œ(TensorFlow)ì—ì„œëŠ” [`tf.nn.rnn_cell.BasicLSTMCell`](https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/BasicLSTMCell)ì„ ì´ìš©í•´ LSTM ì…€ì„ êµ¬í˜„í•  ìˆ˜ ìˆìœ¼ë©°, `BasicLSTMCell` ì‚¬ìš©ë²•ì€ '[07-1. ìˆœí™˜ ì‹ ê²½ë§(RNN)](http://excelsior-cjh.tistory.com/183)'ì—ì„œì˜ ì˜ˆì œì—ì„œ ì•„ë˜ì˜ ì½”ë“œì™€ ê°™ì´ `BasicRNNCell` â†’ `BasicLSTMCell`ë¡œ ë°”ê¿”ì£¼ë©´ ëœë‹¤.\n",
    "\n",
    "```python\n",
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=n_neurons)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# ì¼ê´€ëœ ì¶œë ¥ì„ ìœ„í•´ ìœ ì‚¬ë‚œìˆ˜ ì´ˆê¸°í™”\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# í•œê¸€ì¶œë ¥\n",
    "# matplotlib.rc('font', family='AppleGothic')  # MacOS\n",
    "matplotlib.rc('font', family='Malgun Gothic')  # Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape : (55000, 784)\n",
      "valid_x.shape : (5000, 28, 28)\n",
      "test_x.shape : (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# Layer Params #\n",
    "################\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "n_layers = 3\n",
    "\n",
    "# MNIST Data Load\n",
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
    "train_x = train_x.astype(np.float32).reshape(-1, 28*28) / 255.0  # (784,)\n",
    "test_x = test_x.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "train_y = train_y.astype(np.int32)\n",
    "test_y = test_y.astype(np.int32)\n",
    "valid_x, train_x = train_x[:5000], train_x[5000:]\n",
    "valid_y, train_y = train_y[:5000], train_y[5000:]\n",
    "test_x = test_x.reshape([-1, n_steps, n_inputs])\n",
    "valid_x = valid_x.reshape([-1, n_steps, n_inputs])\n",
    "\n",
    "print('train_x.shape :', train_x.shape)\n",
    "print('valid_x.shape :', valid_x.shape)\n",
    "print('test_x.shape :', test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-batch\n",
    "def shuffle_batch(features, labels, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(features))\n",
    "    n_batches = len(features) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        batch_x, batch_y = features[batch_idx], labels[batch_idx]\n",
    "        yield batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "labels = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# LSTM Model\n",
    "lstm_cells = [tf.nn.rnn_cell.LSTMCell(num_units=n_neurons)\n",
    "              for layer in range(n_layers)]\n",
    "multi_cell = tf.nn.rnn_cell.MultiRNNCell(lstm_cells)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, inputs, dtype=tf.float32)\n",
    "top_layer_h_state = states[-1][1]\n",
    "# dense layer\n",
    "logits = tf.layers.dense(top_layer_h_state, n_outputs)  # states = outputs[-1]\n",
    "\n",
    "# loss\n",
    "xentropy = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "\n",
    "################\n",
    "# Train Params #\n",
    "################\n",
    "learning_rate = 0.001\n",
    "n_epochs = 5\n",
    "batch_size = 150\n",
    "\n",
    "# optimizer\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(xentropy)\n",
    "\n",
    "# metric\n",
    "correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_x, batch_y in shuffle_batch(train_x, train_y, batch_size):\n",
    "            batch_x = batch_x.reshape([-1, n_steps, n_inputs])\n",
    "            sess.run(train_op, \n",
    "                     feed_dict={inputs: batch_x, labels: batch_y})\n",
    "        acc_batch = accuracy.eval(feed_dict={inputs: batch_x, labels: batch_y})\n",
    "        acc_valid = accuracy.eval(feed_dict={inputs: valid_x, labels: valid_y})\n",
    "        loss_batch = xentropy.eval(feed_dict={inputs: batch_x, labels: batch_y})\n",
    "        print('epoch : {:03d}'.format(epoch),\n",
    "              'acc_batch : {:.4f}, acc_valid : {:.4f}'.format(acc_batch, acc_valid),\n",
    "              'loss_batch : {:.4f}'.format(loss_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ‘Š14.2.2 í•í™€(peephole) ì—°ê²°\n",
    "\n",
    "í•í™€ ì—°ê²°(peephole connection)ì€ 2000ë…„ì— F. Gersì™€ J.Schmidhuberê°€ ['Recurrent Nets that and Count'](ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf) ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ LSTMì˜ ë³€ì¢…ì´ë‹¤. ê¸°ì¡´ì˜ LSTMì—ì„œ gate controller($\\mathbf{f}_{t}, \\mathbf{i}_{t}, \\mathbf{o}_{t}$)ëŠ” ì…ë ¥ $\\mathbf{x}_{t}$ì™€ ì´ì „ íƒ€ì„ìŠ¤í…ì˜ ë‹¨ê¸° ìƒíƒœ $\\mathbf{h}_{t-1}$ë§Œ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ”ë‹¤. í•˜ì§€ë§Œ ìœ„ì˜ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ í•í™€ ì—°ê²°ì„ ì•„ë˜ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ ì—°ê²° í•´ì£¼ë©´ì„œ gate controllerì— ì´ì „ íƒ€ì„ìŠ¤í…ì˜ ì¥ê¸° ìƒíƒœ $\\mathbf{c}_{t-1}$ê°€ ì…ë ¥ìœ¼ë¡œ ì¶”ê°€ë˜ë©°, ì¢€ ë” ë§ì€ ë§¥ë½(context)ë¥¼ ì¸ì‹í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "\\mathbf{f}_{t} & = & \\sigma \\left( \\mathbf{W}_{cf}^{T} \\cdot \\mathbf{c}_{t-1} + \\mathbf{W}_{xf}^{T} \\cdot \\mathbf{x}_{t} + \\mathbf{W}_{hf}^{T} \\cdot \\mathbf{h}_{t-1} + \\mathbf{b}_{f} \\right) \\\\ \\mathbf{i}_{t} & =  & \\sigma \\left( \\mathbf{W}_{ci}^{T} \\cdot \\mathbf{c}_{t-1} + \\mathbf{W}_{xi}^{T} \\cdot \\mathbf{x}_{t} + \\mathbf{W}_{hi}^{T} \\cdot \\mathbf{h}_{t-1} + \\mathbf{b}_{i} \\right) \\\\ \\mathbf{o}_{t} & = & \\sigma \\left( \\mathbf{W}_{co}^{T} \\cdot \\mathbf{c}_{t-1} + \\mathbf{W}_{xo}^{T} \\cdot \\mathbf{x}_{t} + \\mathbf{W}_{ho}^{T} \\cdot \\mathbf{h}_{t-1} + \\mathbf{b}_{o} \\right)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "![peephole connection](./images/lstm02.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í…ì„œí”Œë¡œì—ì„œ í•í™€ ì—°ê²°ì„ êµ¬í˜„í•˜ê¸° ìœ„í•´ì„œëŠ” `BasicLSTMCell` ëŒ€ì‹  [`LSTMCell`](https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/LSTMCell)ì„ ì‚¬ìš©í•˜ê³  `use_peepholes`ì¸ìë¥¼ `True`ë¡œ ì„¤ì •í•˜ë©´ ëœë‹¤.\n",
    "\n",
    "```python\n",
    "# Use peephole\n",
    "lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=n_neurons, use_peepholes=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‘Š14.3. GRU Cell\n",
    "\n",
    "**GRU(Gated Recurrent Unit)** ì…€ì€ 2014ë…„ì— K. Cho(ì¡°ê²½í˜„) ë“±ì— ì˜í•´ ['ì´ ë…¼ë¬¸'](https://arxiv.org/pdf/1406.1078v3.pdf)ì—ì„œ ì œì•ˆëœ LSTM ì…€ì˜ **ê°„ì†Œí™”ëœ ë²„ì „**ì´ë¼ê³  í•  ìˆ˜ ìˆìœ¼ë©°, ë‹¤ìŒì˜ ê·¸ë¦¼ê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ ê°€ì§„ë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "![GRU](./images/gru.PNG)\n",
    "\n",
    "\n",
    "\n",
    "- LSTM Cellì—ì„œì˜ ë‘ ìƒíƒœ ë²¡í„° $\\mathbf{c}_{t}$ì™€ $\\mathbf{h}_{t}$ê°€ í•˜ë‚˜ì˜ ë²¡í„° $\\mathbf{h}_{t}$ë¡œ í•©ì³ì¡Œë‹¤.\n",
    "- í•˜ë‚˜ì˜ gate controllerì¸ $\\mathbf{z}_{t}$ê°€ **forget**ê³¼ **input** ê²Œì´íŠ¸(gate)ë¥¼ ëª¨ë‘ ì œì–´í•œë‹¤.  $\\mathbf{z}_{t}$ê°€ `1`ì„ ì¶œë ¥í•˜ë©´ forget ê²Œì´íŠ¸ê°€ ì—´ë¦¬ê³  input ê²Œì´íŠ¸ê°€ ë‹«íˆë©°, $\\mathbf{z}_{t}$ê°€ `0`ì¼ ê²½ìš° ë°˜ëŒ€ë¡œ forget ê²Œì´íŠ¸ê°€ ë‹«íˆê³  input ê²Œì´íŠ¸ê°€ ì—´ë¦°ë‹¤. ì¦‰, ì´ì „($t-1$)ì˜ ê¸°ì–µì´ ì €ì¥ ë ë•Œ ë§ˆë‹¤ íƒ€ì„ ìŠ¤í… $t$ì˜ ì…ë ¥ì€ ì‚­ì œëœë‹¤. \n",
    "- GRU ì…€ì€ output ê²Œì´íŠ¸ê°€ ì—†ì–´ ì „ì²´ ìƒíƒœ ë²¡í„° $\\mathbf{h}_{t}$ê°€ íƒ€ì„ ìŠ¤í…ë§ˆë‹¤ ì¶œë ¥ë˜ë©°, ì´ì „ ìƒíƒœ $\\mathbf{h}_{t-1}$ì˜ ì–´ëŠ ë¶€ë¶„ì´ ì¶œë ¥ë ì§€ ì œì–´í•˜ëŠ” ìƒˆë¡œìš´ gate controllerì¸ $\\mathbf{r}_{t}$ê°€ ìˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU ì…€ì˜ ìƒíƒœ(state)ì™€ ê° ë ˆì´ì–´ì˜ ì¶œë ¥ì„ ê³„ì‚°í•˜ëŠ” ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "\\mathbf{r}_{t} & = & \\sigma \\left( \\mathbf{W}_{xr}^{T} \\cdot \\mathbf{x}_{t} + \\mathbf{W}_{hr}^{T} \\cdot \\mathbf{h}_{t-1} + \\mathbf{b}_{r} \\right) \\\\ \\mathbf{z}_{t} & =  & \\sigma \\left( \\mathbf{W}_{xz}^{T} \\cdot \\mathbf{x}_{t} + \\mathbf{W}_{hz}^{T} \\cdot \\mathbf{h}_{t-1} + \\mathbf{b}_{z} \\right) \\\\ \\mathbf{g}_{t} & = & \\tanh \\left( \\mathbf{W}_{xg}^{T} \\cdot \\mathbf{x}_{t} + \\mathbf{W}_{hg}^{T} \\cdot \\left( \\mathbf{r}_{t} \\otimes \\mathbf{h}_{t-1} \\right) + \\mathbf{b}_{g} \\right) \\\\ \\mathbf{h}_{t} & = & \\mathbf{z}_{t} \\otimes \\mathbf{h}_{t-1} + \\left( 1 - \\mathbf{z}_{t} \\right) \\otimes \\mathbf{g}_{t}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í…ì„œí”Œë¡œì—ì„œ GRU ì…€ì€ [`tf.nn.rnn_cell.GRUCell`](https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/GRUCell)ì„ ì´ìš©í•´ ë‹¤ìŒê³¼ ê°™ì´ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "```python\n",
    "# GRU Cell\n",
    "gru_cell = tf.nn.rnn_cell.GRUCell(num_units=n_neurons)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ‘Š14.4. ë§ˆë¬´ë¦¬\n",
    "\n",
    "ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” RNNì˜ ë¬¸ì œì¸ BPTTì™€ Long-Term Dependency ë¬¸ì œì— ëŒ€í•´ ì•Œì•„ ë³´ì•˜ê³ , ê·¸ë¦¬ê³  RNNì˜ ë³€í˜•ì¸ LSTM, LSTMì˜ ë³€í˜•ì¸ GRUì— ëŒ€í•´ ì•Œì•„ë³´ì•˜ë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
