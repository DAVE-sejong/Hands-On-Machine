{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지도학습 : 알고리즘에 주입하는 훈련 데이터에 레이블이라는 원하는 답이 포함\n",
    "분류가 전형적인 지도학습, 예측변수라 불리는 특성을 사용해 중고차 가격같은 \n",
    "타깃 수치를 예측하는 회귀도 포함\n",
    "\n",
    "로지스틱 회귀는 클래스에 속할 확률을 출력한다.\n",
    "\n",
    "차원축소 : 상관관계가 있는 여러 특성을 하나로 합친다.\n",
    "\n",
    "### 1.3.1 지도학습과 비지도학습\n",
    "#### 비지도 학습 \n",
    "1. 시각화 알고리즘 : 레이블이 없는 대규모의 고차원 데이터를 널으면 \n",
    "                     도식화가 가능한 2D나 3D 표현을 만들어준다.\n",
    "2. 차원 축소 : 상관관계가 있는 여러 특성을 하나로 합치는 것 ex) 차의 주행거리와 연식\n",
    "3. 이상치 탐지 : 학습 알고리즘에 주입라기 전에 데이터셋에서 이상한 값을 자동으로 제거\n",
    "4. 연관 규칙 학습 : 특성간의 관계를 찾아낸다.\n",
    "\n",
    "#### 준지도 학습\n",
    "대부분의 준지도 학습 알고리즘은 지도 학습과 비지도 학습의 조합으로 이뤄져 있다.\n",
    "심층 신뢰 신경망은 여러 겹으로 쌓은 제한된 볼츠만 머신이라 불리는 비지도 학습에 기초한다.\n",
    "제한된 볼츠만 머신은 비지도 학습 방식으로 순차적으로 훈련된 다음 전체 시스템이\n",
    "지도학습 방식으로 조정된다.\n",
    "\n",
    "#### 강화학습\n",
    "학습하는 시스템을 에이전트라 부르며\n",
    "환경을 관찰해서 행동을 실해아고 그 결과로 보상을 받는다.\n",
    "시간이 지나면서 가장 큰 보상을 얻기 위해 정책이라 부르는 최상의 전략을 학습한다.\n",
    "정책은 주어진 상황에서 에이전트가 어떤 행동을 선택해야 할지 정의한다.\n",
    "\n",
    "### 1.3.2 배치학습과 온라인학습\n",
    "배치 학습 : 시스템이 점진적으로 학습할 수 없다. 가용한 데이터를 모두 사용해 훈련해야 한다.\n",
    "시간과 자원을 많이 소모하므로 주로 오프라인에서 수행\n",
    "\n",
    "온라인 학습 : 데이터를 순차적으로 한 개씩 또는 미니배치라 불리는 작은 묶음 단위로 주입하여 \n",
    "시스템 훈련시킨다. 새로운 데이터 샘플을 학습하면 학습이 끝난 데이터는 더 이상 필요하지\n",
    "않으므로 버리면 된다. 많은 공간을 절약할 수 있다.\n",
    "\n",
    "온라인 학습 시스템에서 중요한 파라미터 하나는 변화하는 데이터에 얼마나 빠르게 적응하는 학습률이다.\n",
    "학습률을 높게 하면 시스템이 데이터에 빠르게 적응하지만 데이터를 금방 잊는다.\n",
    "학습률이 낮으면 시스템의 관성이 더 커져서 더 느리게 학습한다. 하지만 대표성없는 \n",
    "데이터 포인트에 덜 민감해진다.\n",
    "\n",
    "### 1.3.3 사례 기반 학습과 모델 기반 학습\n",
    "어떻게 일반화 되는가에 따라 분류할 수 있다.\n",
    "\n",
    "사례 기반 학습 : 단순히 기억하는 방식.\n",
    "사용자가 스팸이라고 지정한 메일과 동일한 모든 메일을 스팸으로 분류\n",
    "메일 사이의 유사도를 측정하는 방식으로 구분하는 방법도 있다.\n",
    "\n",
    "모델 기반 학습 : 샘플들의 모델을 만들어 예측에 사용하는 것\n",
    "\n",
    "훈련 : 데이터에 가장 맞는 파라미터를 찾는 과정\n",
    "\n",
    "### 1.4 머신러닝의 주요 도전 과제\n",
    "#### 1.4.1 충분하지 않은 양의 훈련 데이터\n",
    "#### 1.4.2 대표성 없는 훈련 데이터\n",
    "#### 1.4.3 낮은 품질의 데이터\n",
    "훈련 데이터가 에러, 이상치, 잡음으로 가득하다면 머신러닝 시스템이 내재된 패턴을 찾기 어렵다.\n",
    "#### 1.4.4 관련 없는 특성\n",
    "훈련 데이터에 관련없는 특성이 적고 관련있는 특성이 충분해야 시스템이 학습할 수 있다.\n",
    "이를 특성 공학이라 한다.\n",
    "#### 1.4.5 훈련 데이터 과대적합\n",
    "과대적합의 해결 방법\n",
    "1. 파라미터 수가 적은 모델을 선택한다.\n",
    "2. 훈련 데이터에 있는 특성 수를 줄인다. \n",
    "3. 모델에 제약을 가해서 단순화시킨다.\n",
    "4. 훈련 데이터를 더 많이 모은다.\n",
    "5. 훈련 데이터의 잡음을 줄인다.\n",
    "#### 1.4.6 훈련 데이터 과소적합\n",
    "과소적합 해결 방법\n",
    "1. 모델 파라미터가 더 많은 강력한 모델을 선택한다.\n",
    "2. 모델의 제약을 줄인다.\n",
    "3. 학습 알고리즘에 더 좋은 특성 제공"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
